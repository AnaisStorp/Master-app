{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP — Réseaux convolutifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce TP, nous allons examiner plusieurs manières de faire de la classification avec des réseaux de neurones. Nous allons d'abord commencer par un réseau de neurones simple, complètement connecté. Puis, nous introduirons les réseaux convolutifs. Les tâches sur lesquelles nous travaillerons sont des tâches de classification, on cherche à *prédire* à quelle classe connue appartient une image, à partir d'un modèle qui se sera *entraîné* sur des données *étiquetées*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consignes :**\n",
    "Le TP est noté et je vous demande un rendu individuel, en indiquant cependant le nom de la personne avec qui vous avez travaillé durant la séance.\n",
    "La remise des travaux s'effectue sur Moodle, au format ipynb ou pdf ([**cliquez ici**](https://moodle-sciences-24.sorbonne-universite.fr/mod/assign/view.php?id=117975)). La date limite est le 4 décembre 2024 à 18h (heure de Paris)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quelques imports généraux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow #j'install trensorflow directement avec vscode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "np.random.seed(1671)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les données MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons dans un premier temps travailler avec la [base bien connue des chiffres MNIST](https://yann.lecun.com/exdb/mnist/). L'intérêt de cette base est notamment d'être intégrée directement dans les bibliothèques de code, ce qui permet de travailler facilement dessus, et de comparer les performances de nos modèles et algorithmes avec d'autres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit le paramètre `NB_CLASSES` : en sortie, il y aura 10 chiffres, nous allons demander une sortie (prédiction) dans l'une des 10 classes (0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "RESHAPED = 784\n",
    "NB_CLASSES = 10  \n",
    "\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = to_categorical(y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Expliquez les traitements faits pour chaque image. Comment considère-t-on les images ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Regardez et commentez le format de `Y_train` et `Y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rxsa1tm9Vih6"
   },
   "source": [
    "## Un premier réseau, avec Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons, dans cette première partie, travailler sur un premier réseau de neurones **qui n'utilisera pas les convolutions**. Le but sera d'apprendre à utiliser des rudiments de la bibliothèque Keras, et d'avoir une première *baseline* de performance. Une *baseline* est une expérience de référence, en général avec un modèle peu complexe, qui permet de percevoir le gain obtenu avec le modèle que l'on souhaite évaluer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La [bibliothèque Keras](https://keras.io/) permet d'interagir en Python avec les algorithmes d'apprentissage les plus connus, notamment Tensorflow, PyTorch. Ces dernières années, Keras a été absorbée par TensorFlow. Keras permet une expérimentation rapide avec les réseaux de neurones, se concentrant sur des aspects haut-niveau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelques imports spécifiques à Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sX5q53LdRXIZ",
    "outputId": "7346896c-9188-4dff-9c40-d4dbe9b6fbe7"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelques paramètres :\n",
    "\n",
    "- VERBOSE : nous souhaitons que l'algorithme nous donne des détails\n",
    "  textuels sur son exécution\n",
    "- NB_EPOCH : nous allons itérer 200 fois pour l'apprentissage de notre réseau\n",
    "- BATCH_SIZE : les images seront regroupées dans des lots d'une\n",
    "  certaine taille\n",
    "- OPTIMIZER : il y a diverses techniques pour paramétrer\n",
    "  l'apprentissage. SGD est la \"stochastic gradient descent\".\n",
    "- VALIDATION_SPLIT : la fraction de données utilisées pour valider notre\n",
    "  entraînement de modèle\n",
    "\n",
    "Une *epoch* désigne le traitement de toutes les données du dataset.\n",
    "Pour paralléliser (et accélérer) les calculs, les données du dataset sont regroupés en *lots* plus petits, de taille `BATCH_SIZE`. Le nombre d'*epoch* `NB_EPOCH` et la taille des lots `BATCH_SIZE` sont des hyper-paramètres de l'apprentissage : il faut les définir (et les ajuster) pour réaliser un apprentissage efficace.\n",
    "\n",
    "Pendant une *epoch*, il y a des itérations, chacune traitant un lot. Par exemple, si une itération traite 10 images d’un ensemble de 1000 images avec une taille de batch de 10, il faudra 100 itérations pour terminer une époque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sX5q53LdRXIZ",
    "outputId": "7346896c-9188-4dff-9c40-d4dbe9b6fbe7"
   },
   "outputs": [],
   "source": [
    "NB_EPOCH = 200\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = SGD()\n",
    "VALIDATION_SPLIT=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le modèle\n",
    "\n",
    "Keras propose plusieurs façons différentes de définir un réseau de neurones. La façon la plus courante pour les réseaux à propagation avant (feedforward), qui empilent les couches de façon séquentielle, est d’utiliser la classe `Sequential()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model` contient représente ainsi un réseau de neurones vide (pour l’instant). Il est possible d’ajouter des couches à l’aide de la méthode add. De nombreuses couches sont prédéfinies dans Keras, comme les couches entièrement connectées (couches linéaires dites Dense) ou les fonctions d’activation standard.\n",
    "\n",
    "Nous allons seulement ajouter une couche Dense, et une activation. Donc pas de couche cachée, dans un premier temps :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sX5q53LdRXIZ",
    "outputId": "7346896c-9188-4dff-9c40-d4dbe9b6fbe7"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(NB_CLASSES, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras permet d'afficher un résumé du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** À quoi correspond le nombre de paramètres affiché ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En plus de la définition de l’architecture, nous avons encore besoin de spécifier deux éléments à Keras avant d’entraîner notre modèle : une fonction de coût (*loss*) et une méthode d’optimisation. Ces paramètres sont spécifiés lors de la phase de compilation du modèle à l’aide de la méthode `.compile()`. Nous allons utiliser l’entropie croisée (`categorical_crossentropy`) comme fonction de coût et la descente de gradient stochastique (*stochastic gradient descent* ou sgd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sX5q53LdRXIZ",
    "outputId": "7346896c-9188-4dff-9c40-d4dbe9b6fbe7"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les méthodes `fit()` et `evaluate()` sont essentielles :\n",
    "- `fit()` lance l'apprentissage sur les données\n",
    "- `evaluate()` permet de calculer automatiquement les performances selon l'indicateur choisi (`metrics`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sX5q53LdRXIZ",
    "outputId": "7346896c-9188-4dff-9c40-d4dbe9b6fbe7"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le modèle entraîné, nous pouvons l'évaluer sur l'ensemble de test qui contient de nouveaux exemples inédits. De cette manière, nous obtenons la valeur minimale atteinte par la fonction objective et la meilleure valeur atteinte par la métrique d'évaluation. \n",
    "\n",
    "L'ensemble d'apprentissage et l'ensemble de test sont, bien entendu, rigoureusement séparés. Il est inutile d'évaluer un modèle sur un exemple qui a déjà été utilisé pour l'apprentissage. L'apprentissage est essentiellement un processus destiné à généraliser des observations inédites et non à mémoriser ce qui est déjà connu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sX5q53LdRXIZ",
    "outputId": "7346896c-9188-4dff-9c40-d4dbe9b6fbe7"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Commenter les résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVPDN0ZRTnqf"
   },
   "source": [
    "### Effet de l'ajout de couches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour modifier le modèle, il vous suffit de reprendre le code quelques lignes plus haut, pour redéfinir `model` et mettre les couches que vous voulez.\n",
    "Dans un premier temps, ajoutez une couche `Dense` dite \"cachée\", car elle n'est pas directement connectée à l'entrée ou à la sortie du réseau. Ajoutez ensuite une couche d'activation `relu`, puis une autre couche cachée, et une autre `relu`.\n",
    "\n",
    "```python\n",
    "N_HIDDEN = 128\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Actualisez le modèle, refaites l'entraînement, et commentez les résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQNMfh61T1QE"
   },
   "source": [
    "**Exercice :** Refaites ce qui précède avec une seule couche cachée.\n",
    "Essayez avec plus de deux couches cachées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Commentez vos résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expériences autour d'autres paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvDsyQJHUJkL"
   },
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En machine-learning, on utilise parfois du \"dropout\", c'est-à-dire que certaines connexions entre deux couches sont \"délaissées\" et n'interviennent pas dans le calcul des poids. Le *dropout* permet (souvent) d'éviter le sur-apprentissage et d'améliorer les performances du modèle.\n",
    "\n",
    "On caractérise le *dropout* par un hyperparamètre, une probabilité de ne pas tenir compte aléatoirement de certaines valeurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Ajoutez une couche `Dropout` avec une probabilité `0.3` après les deux couches d'activation `relu`, dans le modèle précédent. Refaites l'entraînement et commentez.\n",
    "\n",
    "**Optionnel :** On peut s'intéresser à différentes valeurs de dropout, vous pouvez essayer des valeurs entre 0.1 et 0.4, si vous voulez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nombre d'epoch (pas en classe)\n",
    "\n",
    "**Question :** Refaites l'entraînement en changeant le nombre d'*epoch*, en essayant plusieurs valeurs (exemples : 10, 50, 100, 200). Tracez une courbe des performances obtenues pour un des modèles ci-dessus (ie, l'accuracy en fonction du nombre d'epoch). Vous n'êtes pas obligés de traver la courbe avec `matplotlib`, si vous êtes plus à l'aise avec un tableur (mais dans ce cas, il faudra bien intégrer dans ce notebook votre image obtenu via le tableur)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimiseur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a plusieurs techniques pour optimiser l'apprentissage, nous avons commencé avec une \"simple\" descente de gradient stochastique.\n",
    "\n",
    "**Question :** Essayez de passer de la `SGD` à `Adam()`, et commentez les résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nombre de neurones dans les couches cachées (pas en classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Essayez des valeurs différentes pour le nombre de neurones dans les couches cachées (`N_HIDDEN`), par exemple 32, 64, 256, 512, 1024. Commentez vos résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mk1wOfy8ULY-"
   },
   "source": [
    "#### Taille des lots\n",
    "\n",
    "**Question :** Comme pour les autres paramètres, expérimentez les performances du modèle avec quelques valeurs de `BATCH_SIZE` différentes de celle du début, et commentez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisation (pas d'expérience ici)\n",
    "\n",
    "**Question :** À l’aide de la [documentation de Keras](https://keras.io/api/layers/core_layers/dense/), expliquez comment sont initialisés les paramètres du modèle pour les couches entièrement connectées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarder un modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : il est possible de sauvegarder un modèle sur le disque, et de le récupérer :\n",
    "```python\n",
    "model.save('monMLP')\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('monMLP')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QtPxqB4VIBp"
   },
   "source": [
    "## Réseaux convolutifs (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrz9zvq6UOrP"
   },
   "source": [
    "Les réseaux convolutifs profonds (Convolutional Neural Networks ou CNN) sont particulièrement adaptés à la reconnaissance d’images, et nous allons expérimenter ce qu'il en est sur la base MNIST, avant de tester sur d'autres images.\n",
    "\n",
    "Nous allons travailler autour d'une architecture CNN particulière, LeNet. La première version de LeNet a été proposée en 1989 par le français Yann LeCun, quelques années après sa thèse à Sorbonne Université (alors appelée Université Pierre-et-Marie-Curie). Yann LeCun a reçu le prix Turing (l'équivalent du prix Nobel pour l'informatique) en 2018 pour ces travaux. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les réseaux convolutifs ont été créés pour travailler efficacement sur des images. Ils reposent sur 3 grandes idées :\n",
    "- le champ réceptif local\n",
    "- les poids partagés\n",
    "- le *pooling*.\n",
    "\n",
    "Le champ réceptif local consiste à relier une sous-matrice de l'image initiale à un neurone unique de la couche suivante, de façon à analyser *localement* l'image, avec une opération de convolution. Il y a plusieurs façons de parcourir une image, avec des masques recouvrants ou non, et différentes façons de gérer les conditions au bord.\n",
    "\n",
    "Les poids partagés consiste à partager les poids dans chaque couche sur toute l'image, de façon à apprendre à repérer des caractéristiques *où qu'elles se trouvent dans l'image*.\n",
    "\n",
    "Le pooling, c'est une façon de réduire la taille des données manipulées, en agrégeant des valeurs locales pour les résumer par un scalaire qui décrit le contenu de cette région.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CHJzLR896Wrs",
    "outputId": "337eaa0a-5267-4e45-b4ad-592ec9caddf5"
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "from tensorflow import keras # Import Keras from TensorFlow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense # Imported layers directly from keras.layers\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1671)  # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On travaille toujours avec MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_ROWS, IMG_COLS = 28, 28 # input image dimensions\n",
    "NB_CLASSES = 10  # number of outputs = number of digits\n",
    "# The input shape needs to be changed to reflect NHWC (Number of samples, Height, Width, Channels)\n",
    "# Since mnist is grayscale it only has 1 channel.\n",
    "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 1)\n",
    "print(INPUT_SHAPE)\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, NB_CLASSES)\n",
    "y_test = to_categorical(y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Remarquez qu'il y a eu une modification des données initiales, elles ne sont plus utilisées comme précédemment. Comment sont-elles organisées ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZO9dsy06P6F"
   },
   "source": [
    "### Le modèle LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici l'archietcture du modèle LeNet :\n",
    "[img](http://raphael.fournier-sniehotta.fr/files/dcrn/images/LeNet5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En fait, nous allons travailler sur une variante de cette architecture, avec des paramètres légèrement différents ici et là. Voici une classe implémentant cette architecture. Vous devriez commencer à être familiers avec l'empilement séquentiel des couches, les unes après les autres.\n",
    "\n",
    "Il y a des couches de [convolution `Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/) et de [*pooling* `MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/), dont vous trouverez la documentation en cliquant sur les liens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CHJzLR896Wrs",
    "outputId": "337eaa0a-5267-4e45-b4ad-592ec9caddf5"
   },
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "\t@staticmethod\n",
    "\tdef build(input_shape, classes):\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\tconv1 = Conv2D(16,kernel_size=(5, 5),activation='relu',input_shape=(28, 28, 1),padding='valid')\n",
    "\t\tmodel.add(conv1)\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tpool1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "\t\tmodel.add(pool1)\n",
    "\n",
    "\t\tconv2 = Conv2D(32,kernel_size=(5, 5),activation='relu',input_shape=(28, 28, 1),padding='valid')\n",
    "\t\tmodel.add(conv2)\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tpool2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "\t\tmodel.add(pool2)\n",
    "\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(100,  input_dim=784, name='fc1'))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\n",
    "\t\t# a softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisons le modèle : apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CHJzLR896Wrs",
    "outputId": "337eaa0a-5267-4e45-b4ad-592ec9caddf5"
   },
   "outputs": [],
   "source": [
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 100\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Lisez la définition du modèle dans la classe LeNet ci-dessus, et commentez son architecture (ie, détaillez quelles couches sont utilisées, expliquez les tailles d'entrée-sortie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CHJzLR896Wrs",
    "outputId": "337eaa0a-5267-4e45-b4ad-592ec9caddf5"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "\t\tbatch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation\n",
    "\n",
    "Affichons 2 courbes importantes :\n",
    "- l'évolution de la métrique \"accuracy\" à chaque *epoch*\n",
    "- l'évolution de la *loss* (l'erreur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CHJzLR896Wrs",
    "outputId": "337eaa0a-5267-4e45-b4ad-592ec9caddf5"
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VE4VoPPvlh3L"
   },
   "source": [
    "**Question :** Commentez ces courbes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance de la quantité de données d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour bien comprendre l'intérêt de **la quantité de données** dans les modèles profonds, modifiez les données sur lesquelles vous apprenez, pour avoir successivement 5900,\n",
    "3000, 1800, 600, et 300 images (l'ensemble de validation sera toujours *ce qui reste*). L'ensemble de test a toujours 10 000 images.\n",
    "\n",
    "**Question :** Tracez une courbe avec les performances du modèle LeNet en fonction de la taille de l'ensemble d'apprentissage.\n",
    "\n",
    "**Question :** Commentez cette courbe. En particulier, mettez cela en perspective avec l'histoire des réseaux convolutifs, mis au point au début des années 1990, mais pleinement utilisés à partir de 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconnaître des chats et des chiens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons cette fois travailler avec une autre base, la base d'images CIFAR-10, qui contient 60000 images, de dimensions 32x32 (3 canaux RGB), réparties en 10 classes. En particulier, il y a une classe de chats et une classe de chiens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[img](http://raphael.fournier-sniehotta.fr/files/dcrn/images/cifar10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre objectif sera d'être capable de *prédire* la classe d'une nouvelle image, c'est-à-dire de disposer d'un modèle capable de reconnaître un chat ou un chien sur des images qu'il n'a pas vues auparavant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelques paramètres et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez utiliser le code suivant pour afficher quelques images issues des données, avec leurs étiquettes (ie, leurs classes d'appartenance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Select a subset to display\n",
    "num_images = 10  # Number of images to display\n",
    "indices = np.random.choice(len(X_train), num_images, replace=False)\n",
    "\n",
    "# Plot the images\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, idx in enumerate(indices):\n",
    "    img = X_train[idx]\n",
    "    label = classes[y_train[idx][0]]  # Get the class name\n",
    "    file_name = f\"{label}{i+1}.jpg\"  # Create a file-like name\n",
    "    \n",
    "    # Display image\n",
    "    plt.subplot(1, num_images, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(file_name, fontsize=8)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec le code suivant, vous pouvez afficher *une* image, dont l'indice est précisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "image_index = 0\n",
    "label = y_train[image_index][0]  # Get the label from y_train\n",
    "class_name = classes[label]\n",
    "print(f\"Image index: {image_index}\")\n",
    "print(f\"Class: {class_name}\")\n",
    "\n",
    "plt.imshow(X_train[image_index])\n",
    "plt.legend(class_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, nous préparons les données pour apprendre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    " \n",
    "# convert to categorical\n",
    "Y_train = to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Que pensez-vous de cette architecture ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'entraînement\n",
    "\n",
    "Attention, cela peut être assez long, environ 2 minutes par epoch. Réduisez éventuellement le nombre d'epoch avant de lancer la cellule suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "\tmetrics=['accuracy'])\n",
    " \n",
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "\tepochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, \n",
    "\tverbose=VERBOSE)\n",
    " \n",
    "print('Testing...')\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                     batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10.weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Commentez ces résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction à partir d'images de votre choix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On recharge le modèle sauvegardé précédemment (dans le cas d'un TP où les choses sont faites séquentiellement, l'intérêt n'est pas forcément clair, ça le devient si vous avez des interruptions, évidemment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#load model\n",
    "model_architecture = 'cifar10_architecture.json'\n",
    "model_weights = 'cifar10.weights.h5'\n",
    "model = model_from_json(open(model_architecture).read())\n",
    "model.load_weights(model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons tester, qualitativement (c'est-à-dire sur quelques images, sans faire de statistiques), si notre modèle reconnaît des images de chats à partir de photos venant d'autres datasets.\n",
    "\n",
    "Vous pouvez tester avec, par exemple, les urls suivantes :\n",
    "- http://raphael.fournier-sniehotta.fr/files/dcrn/images/cats-dogs-val/cats/cat.2024.jpg\n",
    "- http://raphael.fournier-sniehotta.fr/files/dcrn/images/cats-dogs-val/cats/cat.2082.jpg\n",
    "- etc. (de 2000 à 2499 inclus)\n",
    "\n",
    "À la fin de la cellule, vous aurez un affichage de l'image, redimensionnée en 32x32 pixels. Vous pouvez utiliser l'url complète pour afficher l'image en taille réelle.\n",
    "\n",
    "Vous pouvez aussi trouver l'url d'une image sur le web (par exemple dans une autre catégorie, comme \"avion\"/\"airplane\" ou \"camion\"/\"truck\"), et tester les prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files as FILE\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "url = \"http://raphael.fournier-sniehotta.fr/files/dcrn/images/cats-dogs-val/cats/cat.2082.jpg\"\n",
    "img_data = requests.get(url).content\n",
    "with open('image_name.jpg', 'wb') as handler:\n",
    "    handler.write(img_data)\n",
    "\n",
    "\n",
    "image = Image.open('image_name.jpg')\n",
    "image = image.resize((32, 32)) \n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "img = np.array(image)\n",
    "\n",
    "# Transpose and normalize the image data\n",
    "#img = np.transpose(img, (1, 0, 2)).astype('float32')\n",
    "image = np.array(img) / 255\n",
    "imgs = np.expand_dims(image, axis=0)\n",
    "\n",
    "optim = SGD()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optim,\n",
    "\tmetrics=['accuracy'])\n",
    " \n",
    "predictions = model.predict(imgs)  # Get prediction probabilities\n",
    "predicted_class_index = np.argmax(predictions) #Get the index with the highest probability\n",
    "class_name = classes[predicted_class_index]\n",
    "print(\"cette image de chat est prédite comme appartenant à la classe :\",predicted_class_index,class_name) # Print predicted class index\n",
    "\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.legend(class_name)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
